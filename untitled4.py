# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D-oxH3ESbh7eouSY3pEWXF_MgElY-yC_
"""

! pip install streamlit
! pip install keras
! pip install keras-early-stopping
!pip install mplfinance

import tensorflow as tf
import keras
import yfinance as yf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import datetime as dt
import streamlit as st
import warnings
warnings.filterwarnings('ignore')

# Streamlit page setup
st.title('S&P 500 Stock Analysis')

sp500 = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]

sp500['Symbol'] = sp500['Symbol'].str.replace('.', '-')

symbols_list = sp500['Symbol'].unique().tolist()

end_date = dt.datetime.now()

start_date = pd.to_datetime(end_date)-pd.DateOffset(365*8)

# Use Streamlit's selectbox widget to let the user pick a stock symbol
selected_symbol = st.selectbox('Select a stock symbol:', symbols_list)

df = yf.download(tickers= selected_symbol,
                 period='1y',
                 start=start_date,
                 end=end_date).stack()

df.index.names = ['date', 'ticker']

df_one_symbol = df[df.index.get_level_values('ticker') == selected_symbol]

df.isnull().sum()

# Change to ----> Ask user to pick one stock symbol
#df_one_symbol = df[df.index.get_level_values('ticker') == 'AAPL']

df_one_symbol.fillna(method='ffill', inplace=True)

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler(feature_range=(0,1))

df_scaled = scaler.fit_transform(df_one_symbol['close'].values.reshape(-1,1))

X = []
y = []

for i in range(60, len(df_scaled)):
    X.append(df_scaled[i-60:i, 0])
    y.append(df_scaled[i, 0])

train_size = int(len(X)*0.8)
test_size = len(X) - train_size

X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

X_train, y_train = np.array(X_train), np.array(y_train)
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))

from keras.models import Sequential
from keras.layers import Dense, LSTM, Dropout

model = Sequential()

model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))
model.add(LSTM(units=50, return_sequences=True))
model.add(LSTM(units=50, return_sequences=False))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mean_squared_error')
history = model.fit(X_train, y_train, epochs=100, batch_size=25, validation_split=0.2)

from keras.layers import AdditiveAttention, Permute, Reshape, Multiply

model = Sequential()

model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))
model.add(LSTM(units=50, return_sequences=True))

attention = AdditiveAttention(name = 'attention_weight')

model.add(Permute((2,1)))
model.add(Reshape((-1, X_train.shape[1])))
attention_result = attention([model.output, model.output])
multiply_layer = Multiply()([model.output, attention_result])

# Return to original shape
model.add(Permute((2, 1)))
model.add(Reshape((-1, 50)))

# Adding a Flatten layer before the final Dense layer
model.add(tf.keras.layers.Flatten())

# Final Dense layer
model.add(Dense(1))

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
history = model.fit(X_train, y_train, epochs=100, batch_size=25, validation_split=0.2)

from keras.layers import BatchNormalization

model.add(Dropout(0.2))
model.add(BatchNormalization())

model.compile(optimizer='adam', loss='mean_squared_error')

train_size = int(len(df_one_symbol) * 0.8)
train_data, test_data = df_one_symbol[:train_size], df_one_symbol[train_size:]

model.summary()

history = model.fit(X_train, y_train, epochs=100, batch_size=25, validation_split=0.2)

from keras.callbacks import EarlyStopping

early_stopping = EarlyStopping(monitor='val_loss', patience=10) #  restore_best_weights=True
history = model.fit(X_train, y_train, epochs=100, batch_size=25, validation_split=0.2, callbacks=[early_stopping])

from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, TensorBoard, CSVLogger

model_checkpoint = ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_loss', mode='min')
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5) #  min_lr=0.00001
tensorboard = TensorBoard(log_dir='./logs')
csv_logger = CSVLogger('training_log.csv')
callbacks_list = [early_stopping, model_checkpoint, reduce_lr, tensorboard, csv_logger]
history = model.fit(X_train, y_train, epochs=100, batch_size=25, validation_split=0.2, callbacks=callbacks_list)

X_test = np.array(X_test)
y_test = np.array(y_test)
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))
test_loss = model.evaluate(X_test, y_test)
print('Test loss:', test_loss)

from sklearn.metrics import mean_squared_error, mean_absolute_error

# Making predictions
y_pred = model.predict(X_test)

# Calculating MAE and RMSE
mae = mean_absolute_error(y_test, y_pred)
rmse = mean_squared_error(y_test, y_pred, squared=False)

print('MAE:', mae)
print('RMSE:', rmse)

from sklearn.preprocessing import MinMaxScaler

# Fetching the latest 60 days of AAPL stock data
data = yf.download('AAPL', period='60d', interval='1d')

# Selecting the 'Close' price and converting to numpy array
closing_prices = data['Close'].values

# Scaling the data
scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(closing_prices.reshape(-1,1))

# Since we need the last 60 days to predict the next day, we reshape the data accordingly
X_latest = np.array([scaled_data[-60:].reshape(60)])

# Reshaping the data for the model (adding batch dimension)
X_latest = np.reshape(X_latest, (X_latest.shape[0], X_latest.shape[1], 1))

# Making predictions for the next 4 candles
predicted_stock_price = model.predict(X_latest)
predicted_stock_price = scaler.inverse_transform(predicted_stock_price)

print("Predicted Stock Prices for the next 4 days: ", predicted_stock_price)

# Fetch the latest 60 days of AAPL stock data
data = yf.download('AAPL', period='60d', interval='1d')

# Select 'Close' price and scale it
closing_prices = data['Close'].values.reshape(-1, 1)
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(closing_prices)

# Predict the next 4 days iteratively
predicted_prices = []
current_batch = scaled_data[-60:].reshape(1, 60, 1)  # Most recent 60 days

for i in range(4):  # Predicting 4 days
    # Get the prediction (next day)
    next_prediction = model.predict(current_batch)

    # Reshape the prediction to fit the batch dimension
    next_prediction_reshaped = next_prediction.reshape(1, 1, 1)

    # Append the prediction to the batch used for predicting
    current_batch = np.append(current_batch[:, 1:, :], next_prediction_reshaped, axis=1)

    # Inverse transform the prediction to the original price scale
    predicted_prices.append(scaler.inverse_transform(next_prediction)[0, 0])

print("Predicted Stock Prices for the next 4 days: ", predicted_prices)

import mplfinance as mpf
import matplotlib.pyplot as plt
import matplotlib.dates as mpl_dates

# Convert only the first level of the MultiIndex to a DatetimeIndex
if isinstance(df_one_symbol.index, pd.MultiIndex):
    # Assuming the first level of the MultiIndex contains the datetime information
    df_one_symbol.index = pd.to_datetime(df_one_symbol.index.get_level_values(0))
else:
    df_one_symbol.index = pd.to_datetime(df_one_symbol.index)

last_date = df_one_symbol.index[-1]
next_day = last_date + pd.DateOffset(days=1)
prediction_dates = pd.date_range(start=next_day, periods=4, freq='D')

# Assuming 'predicted_prices' is your list of predicted prices for the next 4 days
predictions_df = pd.DataFrame(index=prediction_dates, data=predicted_prices, columns=['Close'])

# Now you can plot with mplfinance
mpf.plot(df_one_symbol, type='candle', style='charles', figsize=(10, 6), title='Stock Price Prediction')

plt.figure(figsize=(10, 6))
plt.plot(predictions_df.index, predictions_df['Close'], marker='o', linestyle='-', color='red')
plt.xlabel('Date')
plt.ylabel('Price')
plt.title('Stock Price Prediction')
plt.grid(True)
plt.show()

closing_price = df_one_symbol['close'].values.reshape(-1, 1)
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(closing_price)

# Combining both actual and predicted data
combined_data = pd.concat([df_one_symbol['close'], predictions_df['Close']])
combined_data = combined_data[-64:] # Last 60 days of actual data + 4 days of predictions

# Plotting the data
plt.figure(figsize=(10,6))
plt.plot(combined_data, linestyle='-', marker='o', color='blue')
plt.title("AAPL Stock Price: Last 60 Days and Next 4 Days Predicted")
plt.show()

# Plotting the actual data
plt.figure(figsize=(10,6))
plt.plot(df_one_symbol.index[-60:], df_one_symbol['close'][-60:], linestyle='-', marker='o', color='blue', label='Actual Data')

# Plotting the predicted data
plt.plot(prediction_dates, predicted_prices, linestyle='-', marker='o', color='red', label='Predicted Data')

plt.title(f" Stock Price: Last 60 Days and Next 4 Days Predicted")
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.show()